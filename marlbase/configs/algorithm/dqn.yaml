# @package _global_

algorithm:
  _target_: dqn.train.main
  name: "dqn"
  model:
    _target_: dqn.model.QNetwork
    layers:
      - 128
      - 128
    parameter_sharing: True # True/False/List[int] (seps_indices)
    use_orthogonal_init: True
    use_rnn: False
    device: "cpu"  # a pytorch device ("cpu" or "cuda")

  training_start: 2000
  buffer_size: 10000  # number of *episodes* to store in the replay buffer

  optimizer: "Adam"
  lr: 3e-4
  gamma: 0.99
  batch_size: 32
  double_q: True

  grad_clip: 1.0

  use_proper_termination: False  # True/ False
  standardise_returns: False
  standardise_rewards: True

  eps_decay_style: "linear"  # "linear" or "exponential"
  eps_decay_over: 0.5  # fraction of total steps over which to decay epsilon
  eps_start: 1.0
  eps_end: 0.05
  eps_exp_decay_rate: 6.5  # exponential decay rate (ignored for linear decay)
  eps_evaluation: 0.05

  target_update_interval_or_tau: 200
